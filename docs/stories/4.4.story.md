# Story 4.4: Training Job (Docker + Script)

## Status

Done

## Story

**As a** Data Scientist,
**I want** a Docker container that fine-tunes YOLOv8 on the new dataset,
**So that** the model improves over time based on human-verified annotations.

## Context

With the Training Controller (4.3) now able to trigger retraining jobs when enough verified annotations accumulate, we need the actual training job that will:
1. Download the dataset and new annotations from MinIO
2. Fine-tune the YOLOv8 model
3. Validate performance on a held-out test set
4. Upload the new model artifacts to MinIO

This job will be executed as a Kubernetes Job triggered by the Training Controller.

## Acceptance Criteria

### 1. Docker Image Creation
- [x] Create Docker image `sentinel-training` with PyTorch/Ultralytics dependencies.
- [x] Use Python 3.11 base image.
- [x] Include all necessary ML dependencies (ultralytics, torch, onnx).

### 2. Training Script (`train.py`)
- [x] Downloads dataset + new annotations from MinIO.
- [x] Runs `yolo train` with appropriate configuration.
- [x] Validates mAP on held-out test set.
- [x] Uploads new `.pt` and `.onnx` model to MinIO (`v{N+1}`).

### 3. Dataset Handling
- [x] Connect to MinIO to retrieve training images and annotations.
- [x] Format data in YOLO-compatible structure (images + labels).
- [x] Split data appropriately for training and validation.

### 4. Model Versioning
- [x] Track model versions (v1, v2, v3...).
- [x] Store metadata (mAP, training date, number of images) alongside model.
- [x] Upload both `.pt` (PyTorch) and `.onnx` (inference) formats.

## Tasks / Subtasks

- [x] **Task 1: Create Training Job Service Structure** (AC: 1)
  - [x] Create `services/training-job/` directory structure
  - [x] Create `requirements.txt` with dependencies (ultralytics, torch, minio, onnx)
  - [x] Create base `Dockerfile` with Python 3.11 and GPU support
  
- [x] **Task 2: Implement MinIO Data Handler** (AC: 2, 3)
  - [x] Create `src/data_handler.py` with MinIO client
  - [x] Implement `download_dataset()` function
  - [x] Implement `download_annotations()` to get verified annotations
  - [x] Create YOLO-compatible directory structure (images/, labels/)
  
- [x] **Task 3: Implement Training Script** (AC: 2)
  - [x] Create `src/train.py` as main entry point
  - [x] Configure YOLOv8 training parameters (epochs, batch size, etc.)
  - [x] Implement training loop using Ultralytics API
  - [x] Add logging for training progress
  
- [x] **Task 4: Implement Validation and Metrics** (AC: 2)
  - [x] Implement validation on held-out test set
  - [x] Calculate and log mAP metrics
  - [x] Compare against previous model performance
  - [x] Implement early stopping if performance degrades
  
- [x] **Task 5: Implement Model Export and Upload** (AC: 2, 4)
  - [x] Export trained model to `.pt` format
  - [x] Export trained model to `.onnx` format for inference
  - [x] Create `src/model_uploader.py` for MinIO upload
  - [x] Implement version incrementing logic (v{N} -> v{N+1})
  - [x] Upload model metadata (mAP, training date, image count)
  
- [x] **Task 6: Create Kubernetes Job Manifest** (AC: 1)
  - [x] Create `k8s/jobs/training-job.yaml` template
  - [x] Configure resource requests/limits (GPU if available)
  - [x] Set appropriate labels (`app=sentinel-training`)
  - [x] Configure environment variables for MinIO connection
  
- [x] **Task 7: Write Unit Tests** (AC: All)
  - [x] Test data handler with mocked MinIO
  - [x] Test model versioning logic
  - [x] Test training configuration validation
  - [x] Test export functionality

## Dev Notes

### Previous Story Insights
From Story 4.3 (Training Controller Logic):
- Training jobs are triggered via Kubernetes `batch/v1` Job API
- Job naming convention: `sentinel-training-{timestamp}`
- Jobs must have label `app=sentinel-training` for concurrency control
- Controller uses placeholder image; this story provides the real implementation
[Source: 4.3.story.md#Dev Agent Record]

### File Locations
- Service location: `services/training-job/` [Source: architecture/source-tree.md#Epic to Source Mapping]
- K8s Job manifest: `k8s/jobs/training-job.yaml` [Source: architecture/source-tree.md#Kubernetes Manifests]
- Standard service structure applies:
  ```
  services/training-job/
  ├── src/
  ├── tests/
  ├── Dockerfile
  └── requirements.txt
  ```
  [Source: architecture/source-tree.md#Standard Service Structure]

### Technology Stack
- **Language**: Python 3.11 [Source: architecture/tech-stack.md]
- **ML Framework**: Ultralytics (YOLOv8) [Source: architecture/tech-stack.md#ML Runtime]
- **Object Storage**: MinIO [Source: architecture/tech-stack.md]
- **Container**: Docker 24+ [Source: architecture/tech-stack.md]

### Coding Standards
- **Formatter**: Black
- **Linter**: Flake8 / Ruff
- **Type Hinting**: Required for all function signatures
- **Docstrings**: Google Style for all public modules and functions
- **Testing**: Pytest
[Source: architecture/coding-standards.md]

### Testing Requirements
- Use Pytest for all unit tests
- Mock MinIO client for data handler tests
- Mock Ultralytics API for training tests
- Test files location: `services/training-job/tests/`
[Source: architecture/coding-standards.md#Python]

### Integration Points
- **MinIO**: For dataset download and model upload
- **Training Controller**: This job is triggered by the controller from Story 4.3
- **Inference Service**: Will consume the uploaded ONNX model (future integration)

## Dev Agent Record

### Agent Model Used
Gemini 2.5

### Completion Notes
- Created complete training-job service with MinIO integration
- Implemented YOLOv8 fine-tuning using Ultralytics API
- Added model versioning (v1, v2, v3...) with metadata storage
- Implemented validation with mAP metrics and early stopping
- Created K8s Job manifest with required labels for concurrency control
- All 22 unit tests passing

### File List

**New Files:**
- `services/training-job/Dockerfile`
- `services/training-job/requirements.txt`
- `services/training-job/src/__init__.py`
- `services/training-job/src/config.py`
- `services/training-job/src/data_handler.py`
- `services/training-job/src/train.py`
- `services/training-job/src/validator.py`
- `services/training-job/src/model_uploader.py`
- `services/training-job/tests/__init__.py`
- `services/training-job/tests/test_data_handler.py`
- `services/training-job/tests/test_model_uploader.py`
- `services/training-job/tests/test_validator.py`
- `k8s/jobs/training-job.yaml`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-18 | 1.0 | Initial story draft | Bob (SM) |
| 2026-01-18 | 1.1 | Implementation complete | James (Dev) |

## QA Results

### Review Date: 2026-01-18

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall: EXCELLENT** - The implementation demonstrates high-quality engineering practices with well-structured modular design, comprehensive type hints, and Google-style docstrings throughout. The code follows Python best practices and the project's coding standards.

**Highlights:**
- Clean separation of concerns across modules (data_handler, validator, model_uploader, train)
- Proper use of `pydantic-settings` for configuration management
- Comprehensive error handling with MinIO S3Error exceptions
- Well-designed dataclasses for ValidationResult
- Proper logging throughout all modules

### Refactoring Performed

None required - the implementation is clean and well-structured.

### Compliance Check

- Coding Standards: ✓ Black formatting, type hints, Google-style docstrings
- Project Structure: ✓ Follows `services/{name}/` standard with src/, tests/, Dockerfile, requirements.txt
- Testing Strategy: ✓ 22 unit tests with proper mocking of MinIO client
- All ACs Met: ✓ All 4 acceptance criteria fully implemented

### Improvements Checklist

- [x] All modules have comprehensive type hints
- [x] All public functions have Google-style docstrings
- [x] Proper error handling for MinIO operations
- [x] Model versioning with v{N} convention
- [x] Metadata storage (mAP, training date, image count)
- [x] K8s Job manifest with required labels (`app=sentinel-training`)
- [ ] **Consider** adding integration tests with a real MinIO instance for CI/CD
- [ ] **Consider** adding linting with Ruff to the testing workflow
- [ ] **Consider** adding retry logic for MinIO operations in production

### Security Review

- ✓ No hardcoded credentials - all MinIO credentials loaded from environment/secrets
- ✓ K8s Job manifest uses SecretKeyRef for credentials
- ✓ No sensitive data logged

### Performance Considerations

- ✓ Batch download from MinIO is efficient
- ✓ Training uses Ultralytics built-in optimizations
- ✓ Early stopping prevents wasted compute on degraded models
- ✓ EmptyDir volumes with size limits prevent disk exhaustion

### Files Modified During Review

None - no modifications required.

### Gate Status

Gate: **PASS** → docs/qa/gates/4.4-training-job.yml

### Recommended Status

✓ **Ready for Done** - All acceptance criteria met, 22 tests passing, code quality excellent.
